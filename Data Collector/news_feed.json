[
    {
        "source": "Reddit/r/MachineLearning",
        "title": "[D] Self-Promotion Thread",
        "link": "https://reddit.com/r/MachineLearning/comments/1qtjnbc/d_selfpromotion_thread/",
        "score": 7,
        "summary": "Please post your personal projects, startups, product placements, collaboration needs, blogs etc.\n\nPlease mention the payment and pricing requirements for products and services.\n\nPlease do not post link shorteners, link aggregator websites , or auto-subscribe links.\n\n\\--\n\nAny abuse of trust will lead to bans.\n\nEncourage others who create new posts for questions to post here instead!\n\nThread will stay alive until next one so keep posting after the date in the title.\n\n\\--\n\nMeta: This is an experiment. If the community doesnt like this, we will cancel it. This is to encourage those in the community to promote their work by not spamming the main threads."
    },
    {
        "source": "Reddit/r/MachineLearning",
        "title": "[D] Monthly Who's Hiring and Who wants to be Hired?",
        "link": "https://reddit.com/r/MachineLearning/comments/1qrrayn/d_monthly_whos_hiring_and_who_wants_to_be_hired/",
        "score": 11,
        "summary": "**For Job Postings** please use this template\n\n&gt;Hiring: \\[Location\\], Salary:\\[\\], \\[Remote | Relocation\\], \\[Full Time | Contract | Part Time\\]    and \\[Brief overview, what you're looking for\\]\n\n**For Those looking for jobs** please use this template\n\n&gt;Want to be Hired: \\[Location\\], Salary Expectation:\\[\\], \\[Remote | Relocation\\], \\[Full Time | Contract | Part Time\\]  Resume: \\[Link to resume\\] and \\[Brief overview, what you're looking for\\]\n\n&amp;#x200B;\n\nPlease remember that this community is geared towards those with experience."
    },
    {
        "source": "Reddit/r/MachineLearning",
        "title": "[D] Papers with no code",
        "link": "https://reddit.com/r/MachineLearning/comments/1rdca7x/d_papers_with_no_code/",
        "score": 34,
        "summary": "I can't believe the amount of papers in major conferences that are accepted without providing any code or evidence to back up their claims. A lot of these papers claim to train huge models and present SOTA performance in the results section/tables but provide no way for anyone to try the model out themselves. Since the models are so expensive/labor intensive to train from scratch, there is no way for anyone to check whether: (1) the results are entirely fabricated; (2) they trained on the test data or (3) there is some other evaluation error in the methodology.\n\nWorse yet is when they provide a link to the code in the text and Openreview page that leads to an inexistent or empty GH repo. For example, [this paper](https://openreview.net/forum?id=GZ7gwOZ6Or) presents a method to generate protein MSAs using RAG at orders magnitude the speed of traditional software; something that would be insanely useful to thousands of BioML researchers. However, while they provide a link to a GH repo, it's completely empty and the authors haven't responded to a single issue or provide a timeline of when they'll release the code."
    },
    {
        "source": "Reddit/r/MachineLearning",
        "title": "[D] Is the move toward Energy-Based Models for reasoning a viable exit from the \"hallucination\" trap of LLMs?",
        "link": "https://reddit.com/r/MachineLearning/comments/1rco6go/d_is_the_move_toward_energybased_models_for/",
        "score": 86,
        "summary": "I\u2019ve been stuck on the recent back-and-forth between Yann LeCun and Demis Hassabis, especially the part about whether LLMs are just \"approximate Turing Machines\" or a fundamental dead end for true reasoning. It\u2019s pretty wild to see LeCun finally putting his money where his mouth is by chairing the board at Logical Intelligence, which seems to be moving away from the autoregressive paradigm entirely.\n\nThey\u2019re building an architecture called Kona that\u2019s rooted in [Energy-Based Models](https://logicalintelligence.com/kona-ebms-energy-based-models). The idea of reasoning via energy minimization instead of next-token prediction is technically interesting because it treats a solution like a physical system seeking equilibrium rather than just a string of guessed words. I was reading [this Wired piece about the shift they're making](https://www.wired.com/story/logical-intelligence-yann-lecun-startup-chart-new-course-agi/), and it really highlights the tension between \"System 1\" generation and \"System 2\" optimization.\n\nIf Kona can actually enforce hard logical constraints through these [EBMs](https://logicalintelligence.com/kona-ebms-energy-based-models), it might finally solve the reliability problem, but I\u2019m still skeptical about the inference-time cost and the scaling laws involved. We all know why autoregressive models won - they are incredibly easy to scale and train. Shifting back to an optimization-first architecture like what Logical Intelligence is doing feels like a high-stakes bet on the \"physics\" of reasoning over the \"fluency\" of language.\n\nBasically, are we ever going to see Energy-Based Models hit the mainstream, or is the 'scale-everything-autoregressive' train moving too fast for anything like Kona to catch up?"
    },
    {
        "source": "Reddit/r/MachineLearning",
        "title": "[D] How much are you using LLMs to summarize/read papers now?",
        "link": "https://reddit.com/r/MachineLearning/comments/1rdcw0o/d_how_much_are_you_using_llms_to_summarizeread/",
        "score": 3,
        "summary": "Until early 2025, I found LLMs pretty bad at summarizing research papers. They would miss key contributions, hallucinate details, or give generic overviews that didn't really capture what mattered. So I mostly avoided using them for paper reading.\n\nHowever, models have improved significantly since then, and I'm starting to reconsider. I've been experimenting more recently, and the quality feels noticeably better, especially for getting a quick gist before deciding whether to deep-read something.\n\nCurious where everyone else stands:\n\n* Do you use LLMs (ChatGPT, Claude, Gemini, etc.) to summarize or help you read papers?\n* If so, how? Quick triage, detailed summaries, Q&amp;A about specific sections, etc.?\n* Do you trust the output enough to skip reading sections, or do you always verify?\n* Any particular models or setups that work well for this?"
    },
    {
        "source": "Reddit/r/LocalLLaMA",
        "title": "AMA with StepFun AI - Ask Us Anything",
        "link": "https://reddit.com/r/LocalLLaMA/comments/1r8snay/ama_with_stepfun_ai_ask_us_anything/",
        "score": 115,
        "summary": "https://preview.redd.it/w8274fg1jekg1.png?width=1785&amp;format=png&amp;auto=webp&amp;s=fadbd0ec26a56e60900f9ed667ae808217d70cf2\n\nHi r/LocalLLaMA !\n\nWe are **StepFun**, the team behind the **Step** family models, including [**Step 3.5 Flash**](https://huggingface.co/collections/stepfun-ai/step-35-flash) and [**Step-3-VL-10B**](https://huggingface.co/collections/stepfun-ai/step3-vl-10b).\n\nWe are super excited to host our first AMA tomorrow in this community. Our participants include CEO, CTO, Chief Scientist, LLM Researchers.\n\n**Participants**\n\n* [u/Ok\\_Reach\\_5122](https://old.reddit.com/u/Ok_Reach_5122) (Co-founder &amp; CEO of StepFun)\n* [u/bobzhuyb](https://old.reddit.com/u/bobzhuyb) (Co-founder &amp; CTO of StepFun)\n* [u/Lost-Nectarine1016](https://old.reddit.com/user/Lost-Nectarine1016) (Co-founder &amp; Chief Scientist of StepFun)\n* [u/Elegant-Sale-1328](https://old.reddit.com/u/Elegant-Sale-1328) (Pre-training)\n* [u/SavingsConclusion298](https://old.reddit.com/u/SavingsConclusion298) (Post-training)\n* [u/Spirited\\_Spirit3387](https://old.reddit.com/u/Spirited_Spirit3387) (Pre-training)\n* [u/These-Nothing-8564](https://www.reddit.com/user/These-Nothing-8564/) (Technical Project Manager)\n* [u/Either-Beyond-7395](https://old.reddit.com/u/Either-Beyond-7395) (Pre-training)\n* [u/Human\\_Ad\\_162](https://old.reddit.com/u/Human_Ad_162) (Pre-training)\n* [u/Icy\\_Dare\\_3866](https://old.reddit.com/u/Icy_Dare_3866) (Post-training)\n* [u/Big-Employee5595](https://old.reddit.com/u/Big-Employee5595) (Agent Algorithms Lead\n\n**The AMA will run 8 - 11 AM PST, Feburary 19th. The StepFun team will monitor and answer questions over the 24 hours after the live session.**"
    },
    {
        "source": "Reddit/r/LocalLLaMA",
        "title": "Best Audio Models - Feb 2026",
        "link": "https://reddit.com/r/LocalLLaMA/comments/1r7bsfd/best_audio_models_feb_2026/",
        "score": 100,
        "summary": "They've been a ton of audio models released of late, the most notable perhaps being Qwen3 TTS. So its time for another **Best Audio Models** megathread\n\nShare what your favorite ASR, TTS, STT, Text to Music models are right now\u00a0**and why.**\n\nGiven the the amount of ambiguity and subjectivity in rating/testing these models, please be as detailed as possible in describing your setup, nature of your usage (how much, personal/professional use), tools/frameworks etc. Closed models like Elevenlabs v3 seem to continue to be a few levels above open models especially for production use cases with long lengths/stability requirements, so comparisons, especially empirical ones are welcome.\n\n**Rules**\n\n* Should be open weights models\n\nPlease use the top level comments to thread your responses."
    },
    {
        "source": "Reddit/r/LocalLLaMA",
        "title": "Distillation when you do it. Training when we do it.",
        "link": "https://reddit.com/r/LocalLLaMA/comments/1rcvimv/distillation_when_you_do_it_training_when_we_do_it/",
        "score": 2551,
        "summary": ""
    },
    {
        "source": "Reddit/r/LocalLLaMA",
        "title": "Anthropic: \"We\u2019ve identified industrial-scale distillation attacks on our models by DeepSeek, Moonshot AI, and MiniMax.\" \ud83d\udea8",
        "link": "https://reddit.com/r/LocalLLaMA/comments/1rcpmwn/anthropic_weve_identified_industrialscale/",
        "score": 4095,
        "summary": ""
    },
    {
        "source": "Reddit/r/LocalLLaMA",
        "title": "Anthropic's recent distillation blog should make anyone only ever want to use local open-weight models; it's scary and dystopian",
        "link": "https://reddit.com/r/LocalLLaMA/comments/1rd8cfw/anthropics_recent_distillation_blog_should_make/",
        "score": 333,
        "summary": "It's quite ironic that they went for the censorship and authoritarian angles here.\n\nFull blog: [https://www.anthropic.com/news/detecting-and-preventing-distillation-attacks](https://www.anthropic.com/news/detecting-and-preventing-distillation-attacks)"
    }
]